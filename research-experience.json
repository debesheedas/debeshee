[
  {
    "company": "Snyk / Invariant Labs",
    "position": "AI Security Research Intern",
    "duration": "July 2025 - Present",
    "logos": [
      {
        "image": "images/snyk-logo.png",
        "alt": "Snyk"
      },
      {
        "image": "images/invariant-logo.jpeg",
        "alt": "Invariant Labs"
      }
    ],
    "description": "Developed a novel instruction-tagger and sanitizer based defence for prompt injection attacks on LLM agents. Evaluations on the Agent Dojo benchmark show an almost perfect defense (reduces Attack Success Rate to only 0.84%) without loss in Utility (and even increases utility in some use cases).",
    "links": []
  },
  {
    "company": "ETH Zurich - SPY Lab",
    "position": "Research Assistant",
    "duration": "Spring 2024 - Present",
    "logos": [
      {
        "image": "images/eth-logo.png",
        "alt": "ETH Zurich"
      }
    ],
    "description": "Research Project: Demonstrated fundamental flaws in evaluation of membership inference (MI) privacy attacks on foundation model LLMs using blind attacks that outperform state-of-the-art MI attacks by 51.2%.",
    "publications": [
      "Publication accepted at Data FM Workshop ICLR '25 and DLSP Workshop IEEE S&P '25: <em>Blind Baselines Beat Membership Inference Attacks for Foundation Models</em>.",
      "Position Paper on MI attacks being incorrectly used for training data proofs: Accepted at IEEE SaTML '25: <em>Membership Inference Attacks Cannot Prove that a Model Was Trained On Your Data</em>"
    ],
    "additional": "Peer-Reviewer for Elsevier Science Direct SoftwareX peer-reviewed journal.",

    "links": []
  },
  {
    "company": "Microsoft",
    "position": "M365 Research Intern",
    "duration": "Spring 2025",
    "logos": [
      {
        "image": "images/microsoft-logo.png",
        "alt": "Microsoft"
      }
    ],
    "description": "Developed a novel approach to Cloud Incident Root Cause Analysis using semi-automatic knowledge graph creation and graph-based retrieval augmented LLM pipeline on 200,000 incident data points. Obtained marginal improvements over the state-of-the-art in-context learning LLM based-tool in production.",
    "links": []
  },
  {
    "company": "IBM Research Labs, India",
    "position": "Summer Research Intern",
    "duration": "Summer 2022 - Spring 2023",
    "logos": [
      {
        "image": "images/ibm-logo.jpg",
        "alt": "IBM Research"
      }
    ],
    "description": "Bachelor's Thesis: Designed novel code-view infused BERT model that achieves a precision of 96% and beats the state-of-the-art by 1% on multiple automated SE tasks - semantic code search, code clone detection, etc.",
    "projects": [
      "Built COMEX, an open-source tool with 140+ stars, to generate multi-view graph code-views for ML models for software engineering"
    ],
    "publications": [
      "IEEE/ACM ASE '23: <em>COMEX: A Tool for Generating Customized Source Code Representations</em>"
    ],

    "links": [
      {
        "text": "COMEX",
        "url": "https://github.com/IBM/tree-sitter-codeviews"
      }
    ]
  }
]
